{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLFLOW integration with DagsHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\Il mio Drive\\\\PROJECTS\\\\Kidney-Tumor-Detection-End-To-End'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect MLFlow url and for security reasons pasted it into .env file. Instructions below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dagshub -> add repo -> remote -> experiments -> copy \"using MLFlow tracking\"\n",
    "\n",
    "- MLFLOW_TRACKING_URI=https://dagshub.com/DavidAlexanderMoe/Kidney-Tumor-Detection-End-To-End.mlflow\n",
    "- MLFLOW_TRACKING_USERNAME=DavidAlexanderMoe\n",
    "- MLFLOW_TRACKING_PASSWORD=d8b4e71758deec52ce96b8105652ddaf6bad36aa\n",
    "- python script.py\n",
    "\n",
    "If someone has this info, he can send his experiments directly to the DagsHub repository.\n",
    "\n",
    "git bash:\n",
    "- export MLFLOW_TRACKING_URI=https://dagshub.com/DavidAlexanderMoe/Kidney-Tumor-Detection-End-To-End.mlflow\n",
    "- export MLFLOW_TRACKING_USERNAME=DavidAlexanderMoe\n",
    "- MLFLOW_TRACKING_PASSWORD=...\n",
    "\n",
    "this info will be required in my main.py\n",
    "\n",
    "#### for remote server only (remote) add this code\n",
    "- remote_server_uri=https://dagshub.com/DavidAlexanderMoe/Kidney-Tumor-Detection-End-To-End.mlflow\n",
    "- mlflow.set_tracking_uri(remote_server_uri)\n",
    "\n",
    "git bash -> python main.py -> mlruns folder will be created\n",
    "\n",
    "- go to dagshub -> experiments -> click on experiment\n",
    "or\n",
    "- go to dagshub -> remote -> experiments -> go to mlflow ui -> mlflow opens (running on local server)\n",
    "\n",
    "run main.py to create another experiment\n",
    "\n",
    "This is powerful since many different people can run different experiments on the same project and track them all in a single dashboard\n",
    "\n",
    "Model monitoring -> different models and versions and decide which to push into production and which is staging for further tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the info and change environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# getenv() -> read the value of the environment variable\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "MLFLOW_TRACKING_USERNAME = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "MLFLOW_TRACKING_PASSWORD = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"]=\"https://dagshub.com/DavidAlexanderMoe/Kidney-Tumor-Detection-End-To-End.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"]=MLFLOW_TRACKING_USERNAME\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"]=MLFLOW_TRACKING_PASSWORD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = tf.keras.models.load_model(\"artifacts/training/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict            # from params.yaml\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CNN_Classifier.constants import *\n",
    "from CNN_Classifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "    \n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model=\"artifacts/training/model.h5\",\n",
    "            training_data=\"artifacts/data_ingestion/Kidney Images\",\n",
    "            mlflow_uri=\"https://dagshub.com/DavidAlexanderMoe/Kidney-Tumor-Detection-End-To-End.mlflow\",\n",
    "            all_params=self.params,\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_batch_size=self.params.BATCH_SIZE\n",
    "        )\n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras         # keras support for mlflow\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    \n",
    "    # make again a valid set generator to separate out my testing data using keras\n",
    "    # copied and pasted from keras documentation\n",
    "    # basically takes my data in artifacts and then prepare TESTING data for me\n",
    "    def _valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.30       # now 0.3\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "    # same thing -> use staticmethod to make this function indipendent and not depend on self and the class\n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "\n",
    "    # evaluate model\n",
    "    def evaluation(self):\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        self._valid_generator()\n",
    "        self.score = model.evaluate(self.valid_generator)\n",
    "        self.save_score()           # to create a json file with the scores\n",
    "    \n",
    "    # save metrics\n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Experiment tracking and model registration with mlflow√π\n",
    "    # copied from mlflow doc and modified for logging\n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        \n",
    "        with mlflow.start_run():            # start tracking\n",
    "            mlflow.log_params(self.config.all_params)           # log parameters and metrics\n",
    "            mlflow.log_metrics(\n",
    "                {\"loss\": self.score[0], \"accuracy\": self.score[1]})\n",
    "            \n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.keras.log_model(self.model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "            else:\n",
    "                mlflow.keras.log_model(self.model, \"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### update pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-18 14:18:08,949: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-11-18 14:18:08,973: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-11-18 14:18:08,973: INFO: common: created directory at: artifacts]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2207 images belonging to 2 classes.\n",
      "138/138 [==============================] - 289s 2s/step - loss: 4.2983 - accuracy: 0.7300\n",
      "[2023-11-18 14:22:59,372: INFO: common: json file saved at: scores.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/11/18 14:23:05 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-18 14:23:08,396: WARNING: save: Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 14). These functions will not be directly callable after loading.]\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\david\\AppData\\Local\\Temp\\tmpvc1wr8e0\\model\\data\\model\\assets\n",
      "[2023-11-18 14:23:09,494: INFO: builder_impl: Assets written to: C:\\Users\\david\\AppData\\Local\\Temp\\tmpvc1wr8e0\\model\\data\\model\\assets]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\david\\miniconda3\\envs\\kidney\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2023/11/18 14:24:28 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 2\n",
      "Created version '2' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_evaluation_config()\n",
    "    evaluation = Evaluation(eval_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "   raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saved json with scores\n",
    "\n",
    "Go to MLFlow -> refresh -> see the experiment\n",
    "\n",
    "Now the point of implementing mlflow tracking: If i am not satisfied with the results (metrics), i can easily change my hyperparameters through the params.yaml file without the need of doing hyperparameter tuning manually. I must run the entire pipeline again (via main.py) since the model.h5 was trained with different parameters.\n",
    "\n",
    "MLFlow -> models -> see model registration. Here you test, test, test and then, when satisfied with the results, you can move the model into production stage by clicking the version of the model and changing the stage.\n",
    "\n",
    "---\n",
    "\n",
    "- Changed epochs from 1 to 2 to see a boost in accuracy, open main.py and run another experiment and see the Version 2 of the model.\n",
    "\n",
    "Run many experiments (lr=0.08, augmentation=false, change batch size, etc.. )\n",
    "\n",
    "Compare the experiments/models directly on mlflow ui through dagshub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Once the pipepline and the main.py are updated, you can main.py different times with different parameters setting them in params.yaml!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
